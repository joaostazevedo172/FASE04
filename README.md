# FIAP - Faculdade de InformÃ¡tica e AdministraÃ§Ã£o Paulista

<p align="center">
<a href= "https://www.fiap.com.br/"><img src="https://tse2.mm.bing.net/th/id/OIP.3xs_MSeNC0T1UOrJaCEqWAHaEK?cb=12&rs=1&pid=ImgDetMain&o=7&rm=3" alt="FIAP - Faculdade de InformÃ¡tica e AdmnistraÃ§Ã£o Paulista" border="0" width=40% height=40%></a>
</p>

<br>

## ğŸ‘¨â€ğŸ“ Integrantes: 
- <a href="#">Maria Luiza Oliveira Carvalho</a> 
- <a href="#">MiriÃ£ Leal Mantovani</a>
- <a href="#">JoÃ£o Pedro Santos Azevedo</a> 
- <a href="#">Rodrigo de Souza Freitas</a>

## ğŸ‘©â€ğŸ« Professores:
### Tutor(a) 
- <a href="https://github.com/SabrinaOtoni">Sabrina Otoni</a>

# ğŸŒ¾ ClassificaÃ§Ã£o Automatizada de GrÃ£os de Trigo

Projeto de Machine Learning aplicando a metodologia **CRISP-DM** para automatizar a classificaÃ§Ã£o de variedades de trigo em cooperativas agrÃ­colas.

---

## ğŸ“‹ Sobre o Projeto

Em cooperativas agrÃ­colas, a classificaÃ§Ã£o de grÃ£os Ã© frequentemente manual, lenta e sujeita a erros. Este projeto busca resolver esse problema usando algoritmos de Aprendizado de MÃ¡quina para classificar **trÃªs variedades de trigo** com base em caracterÃ­sticas fÃ­sicas (geomÃ©tricas).

**Objetivo:** Desenvolver um modelo preditivo capaz de distinguir entre as variedades **Kama**, **Rosa** e **Canadian** com alta precisÃ£o.

---

## ğŸ—‚ï¸ O Conjunto de Dados (Dataset)

Dataset utilizado: **Seeds Dataset â€“ UCI Machine Learning Repository**

- **Amostras:** 210 grÃ£os (70 por variedade)  
- **Atributos (Features):**
  - Ãrea  
  - PerÃ­metro  
  - Compacidade `C = 4Ï€A / PÂ²`  
  - Comprimento do NÃºcleo  
  - Largura do NÃºcleo  
  - Coeficiente de Assimetria  
  - Comprimento do Sulco do NÃºcleo  

---

## âš™ï¸ Metodologia (CRISP-DM)

### **1. Entendimento e PreparaÃ§Ã£o dos Dados**
- AnÃ¡lise ExploratÃ³ria (Histogramas, Boxplots)
- Heatmap de correlaÃ§Ã£o e Pairplot
- PadronizaÃ§Ã£o com **StandardScaler**

### **2. Modelagem**
- DivisÃ£o Treino/Teste: **70/30**
- Modelos treinados:
  - KNN  
  - SVM  
  - Random Forest  
  - Naive Bayes  
  - RegressÃ£o LogÃ­stica

### **3. OtimizaÃ§Ã£o**
- Refinamento de hiperparÃ¢metros via **Grid Search**  
  - Foco em **KNN** e **Random Forest**

### **4. AvaliaÃ§Ã£o e InterpretaÃ§Ã£o**
- MÃ©tricas analisadas: AcurÃ¡cia, F1-Score, Matriz de ConfusÃ£o  
- Estudo de ImportÃ¢ncia das Features

---

## ğŸ“Š Resultados AlcanÃ§ados

### **Desempenho dos Modelos (Teste)**

| Rank | Modelo                     | AcurÃ¡cia | F1-Score |
|------|-----------------------------|----------|----------|
| ğŸ¥‡   | Random Forest (Otimizado)   | 92.06%   | 0.919    |
| ğŸ¥ˆ   | K-Nearest Neighbors (KNN)   | 87.30%   | 0.871    |
| ğŸ¥‰   | Support Vector Machine (SVM) | 87.30%   | 0.871    |

### **Principais Insights**
- O modelo **Random Forest** apresentou o melhor desempenho.  
- A feature **Compacidade** e as dimensÃµes do nÃºcleo foram essenciais para a classificaÃ§Ã£o.  
- O sistema Ã© viÃ¡vel para implantaÃ§Ã£o e supera a consistÃªncia humana em tarefas repetitivas.

---

## ğŸ› ï¸ Tecnologias Utilizadas

- **Linguagem:** Python 3  
- **Ambiente:** Jupyter Notebook / VS Code  
- **Bibliotecas:**
  - `pandas` e `numpy` â€“ ManipulaÃ§Ã£o de dados  
  - `matplotlib` e `seaborn` â€“ VisualizaÃ§Ã£o  
  - `scikit-learn` â€“ Modelagem, prÃ©-processamento, mÃ©tricas  

---

## â–¶ï¸ Como Executar o Projeto

1. Clone o repositÃ³rio ou baixe os arquivos  
2. Instale as dependÃªncias:

   ```bash
   pip install pandas numpy matplotlib seaborn scikit-learn
